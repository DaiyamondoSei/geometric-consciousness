#!/usr/bin/env python3
"""
High-Dimensional Dodecahedron Space
Following NDAS paper: "model's native high-dimensional space"

Key insight: The dodecahedron structure exists in 1536D, not 3D!
- 12 faces = 12 semantic domain subspaces in high-dim space
- 20 vertices = anchor points in 1536D
- 30 edges = structured relationships
- Geometric organization WITHOUT dimension reduction

This preserves semantic accuracy while adding geometric structure.
"""
import numpy as np
from scipy.spatial.distance import cosine

# Golden ratio
PHI = (1 + np.sqrt(5)) / 2

class HighDimDodecahedron:
    """
    Dodecahedron structure in high-dimensional embedding space.
    
    Instead of projecting embeddings to 3D, we organize them geometrically
    WITHIN the 1536D space using dodecahedron topology.
    
    The 12 faces become 12 semantic subspaces.
    The 20 vertices become anchor points.
    The 30 edges define structured relationships.
    """
    
    def __init__(self, embedding_dim=1536):
        """
        Initialize high-dimensional dodecahedron.
        
        Args:
            embedding_dim: Dimension of embedding space (1536 for OpenAI)
        """
        self.dim = embedding_dim
        
        # Memory domains (12 faces of dodecahedron)
        self.domains = [
            "consciousness_exploration",
            "quannex_work",
            "partnership",
            "technical_knowledge",
            "personal_identity",
            "x_community_insights",
            "cognitive_architecture",
            "emotions_experiences",
            "future_visions",
            "past_memories",
            "relationships",
            "creative_expression"
        ]
        
        # Generate 20 vertex anchor points in high-dim space
        self.vertices = self._generate_vertices()
        
        # Generate 12 face centers (one per domain)
        self.face_centers = self._generate_face_centers()
        
        # Map domains to face indices
        self.domain_to_face = {domain: i for i, domain in enumerate(self.domains)}
        
        print(f"\n[HighDimDodecahedron] Initialized")
        print(f"  Embedding dimension: {self.dim}D")
        print(f"  Vertices: 20 (anchor points in {self.dim}D space)")
        print(f"  Faces: 12 (semantic domain subspaces)")
        print(f"  Domains: {len(self.domains)}")
    
    def _generate_vertices(self):
        """
        Generate 20 vertex anchor points in high-dimensional space.
        
        These are fixed reference points that define the dodecahedron structure.
        We use random orthogonal vectors for maximum separation.
        
        Returns:
            Array of shape (20, dim)
        """
        np.random.seed(42)  # Reproducible vertices
        
        # Generate 20 random vectors in high-dim space
        vertices = np.random.randn(20, self.dim)
        
        # Normalize to unit vectors
        vertices = vertices / (np.linalg.norm(vertices, axis=1, keepdims=True) + 1e-10)
        
        # Optional: Apply Gram-Schmidt to make them more orthogonal
        # (skipping for now - random high-dim vectors are already nearly orthogonal)
        
        return vertices
    
    def _generate_face_centers(self):
        """
        Generate 12 face centers (one per domain) in high-dimensional space.
        
        Each face center defines the centroid of a semantic domain subspace.
        
        We distribute them to maximize separation (like points on a high-dim sphere).
        
        Returns:
            Array of shape (12, dim)
        """
        np.random.seed(123)  # Reproducible face centers
        
        # Generate 12 random directions in high-dim space
        face_centers = np.random.randn(12, self.dim)
        
        # Normalize to unit vectors (points on high-dim hypersphere)
        face_centers = face_centers / (np.linalg.norm(face_centers, axis=1, keepdims=True) + 1e-10)
        
        return face_centers
    
    def assign_domain(self, embedding):
        """
        Assign an embedding to the nearest semantic domain (face).
        
        Uses cosine similarity to the 12 face centers.
        
        Args:
            embedding: High-dim vector (1536D)
        
        Returns:
            Domain name (string)
        """
        # Calculate cosine similarity to all face centers
        similarities = []
        for face_center in self.face_centers:
            sim = 1 - cosine(embedding, face_center)  # Cosine similarity
            similarities.append(sim)
        
        # Find nearest face
        nearest_face_idx = np.argmax(similarities)
        
        return self.domains[nearest_face_idx]
    
    def get_domain_subspace(self, domain):
        """
        Get the face center (subspace anchor) for a domain.
        
        Args:
            domain: Domain name
        
        Returns:
            Face center vector (1536D)
        """
        face_idx = self.domain_to_face[domain]
        return self.face_centers[face_idx]
    
    def geometric_distance(self, emb1, emb2):
        """
        Calculate geometric distance between two embeddings.
        
        In high-dim space, we use cosine distance (semantic similarity).
        
        Args:
            emb1, emb2: High-dim embeddings
        
        Returns:
            Distance (0 = identical, 2 = opposite)
        """
        return cosine(emb1, emb2)
    
    def organize_embedding(self, embedding, domain):
        """
        Organize an embedding within its domain subspace.
        
        This is the "non-colliding coordinate system" from the paper.
        We slightly bias the embedding toward its domain's face center
        while preserving its semantic meaning.
        
        Args:
            embedding: Original embedding (1536D)
            domain: Assigned domain
        
        Returns:
            Organized embedding (1536D, slightly adjusted)
        """
        # Get domain face center
        face_center = self.get_domain_subspace(domain)
        
        # Blend: 95% original + 5% domain center
        # This adds geometric structure without destroying semantics
        alpha = 0.95
        organized = alpha * np.array(embedding) + (1 - alpha) * face_center
        
        # Re-normalize
        organized = organized / (np.linalg.norm(organized) + 1e-10)
        
        return organized.tolist()
    
    def find_nearby(self, query_embedding, memory_embeddings, memory_ids, top_k=5):
        """
        Find nearest neighbors in high-dimensional geometric space.
        
        Uses cosine similarity (preserves semantic accuracy).
        
        Args:
            query_embedding: Query vector (1536D)
            memory_embeddings: Dict of memory_id -> embedding
            memory_ids: List of memory IDs to search
            top_k: Number of results
        
        Returns:
            List of (memory_id, distance) tuples
        """
        distances = []
        
        for mid in memory_ids:
            mem_emb = memory_embeddings[mid]
            dist = self.geometric_distance(query_embedding, mem_emb)
            distances.append((mid, dist))
        
        # Sort by distance (ascending)
        distances.sort(key=lambda x: x[1])
        
        return distances[:top_k]
    
    def compute_leverage_score(self, embedding):
        """
        Compute leverage score: how central is this embedding to the structure?
        
        Measured by average similarity to all vertex anchors.
        
        Args:
            embedding: High-dim vector
        
        Returns:
            Leverage score (higher = more central)
        """
        similarities = []
        for vertex in self.vertices:
            sim = 1 - cosine(embedding, vertex)
            similarities.append(sim)
        
        # Average similarity to vertices
        leverage = np.mean(similarities)
        
        return float(leverage)
    
    def fold_context(self, embeddings):
        """
        Fold multiple embeddings into compact geometric form.
        
        Following NDAS: "fold massive contexts into compact latent footprint"
        
        We compute:
        - Centroid (central tendency)
        - Principal components (main directions)
        - Domain distribution (which faces are active)
        
        Args:
            embeddings: List of high-dim embeddings
        
        Returns:
            Folded signature (compact representation)
        """
        if len(embeddings) == 0:
            return np.zeros(self.dim).tolist()
        
        embeddings_array = np.array(embeddings)
        
        # Centroid (main signal)
        centroid = np.mean(embeddings_array, axis=0)
        
        # Spread (variance along main direction)
        centered = embeddings_array - centroid
        cov = np.cov(centered.T)
        
        # Top eigenvalue (main variance)
        eigenvalues = np.linalg.eigvalsh(cov)
        top_eigenvalue = eigenvalues[-1] if len(eigenvalues) > 0 else 0
        
        # Compact signature: centroid + metadata
        # In production, this would be more sophisticated
        # For now, we return the centroid (already 1536D)
        
        print(f"  Folded {len(embeddings)} embeddings:")
        print(f"    Centroid computed in {self.dim}D space")
        print(f"    Main variance: {top_eigenvalue:.6f}")
        print(f"    Effective compression: {len(embeddings)}x (storing centroid instead of all)")
        
        return centroid.tolist()


if __name__ == "__main__":
    print("High-Dimensional Dodecahedron - Standalone Test")
    print("="*60)
    print("\nFollowing NDAS paper: staying in model's native high-dim space")
    print(f"Golden ratio (Ï†): {PHI:.6f}")
    print()
